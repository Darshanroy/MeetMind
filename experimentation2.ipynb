{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Task: \n\n### Implementation of IDEA using yt transcrpits\n\n1. choosing best LLM for our usecase: where usecase=\"summarization of the context\"\n    - **choosen model** :Mistral\n2. Dataset creation\n\n","metadata":{}},{"cell_type":"code","source":"token =\"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\"\nyt_link = \"https://youtu.be/CDZ9REOh2xA?si=HaSORmywGwQA97_T\"","metadata":{"execution":{"iopub.status.busy":"2024-10-19T08:55:25.426642Z","iopub.execute_input":"2024-10-19T08:55:25.427592Z","iopub.status.idle":"2024-10-19T08:55:25.432877Z","shell.execute_reply.started":"2024-10-19T08:55:25.427541Z","shell.execute_reply":"2024-10-19T08:55:25.431336Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"# ! pip install -q langchain langchain_chroma langchain_community langchain_core langchain_huggingface transformers\n# ! pip install -qU langchain_huggingface\n# ! pip install pytube\n# ! pip install --upgrade --quiet  youtube-transcript-api","metadata":{"execution":{"iopub.status.busy":"2024-10-19T08:55:26.112111Z","iopub.execute_input":"2024-10-19T08:55:26.112583Z","iopub.status.idle":"2024-10-19T08:55:26.117837Z","shell.execute_reply.started":"2024-10-19T08:55:26.112541Z","shell.execute_reply":"2024-10-19T08:55:26.116442Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"import os\nimport time\nfrom dotenv import load_dotenv\nfrom langchain.chains import create_history_aware_retriever, create_retrieval_chain\nfrom langchain.chains.combine_documents import create_stuff_documents_chain\nfrom langchain_chroma import Chroma\nfrom langchain_community.llms import HuggingFaceHub\nfrom langchain_community.embeddings import HuggingFaceBgeEmbeddings\nfrom langchain_community.chat_message_histories import ChatMessageHistory\nfrom langchain_community.document_loaders import UnstructuredCSVLoader\nfrom langchain_core.chat_history import BaseChatMessageHistory\nfrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\nfrom langchain_core.runnables.history import RunnableWithMessageHistory\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\nfrom langchain_huggingface.embeddings import HuggingFaceEndpointEmbeddings\nfrom langchain_huggingface import HuggingFaceEndpoint\nfrom langchain.chains import HypotheticalDocumentEmbedder","metadata":{"execution":{"iopub.status.busy":"2024-10-19T08:55:26.612789Z","iopub.execute_input":"2024-10-19T08:55:26.613435Z","iopub.status.idle":"2024-10-19T08:55:26.621917Z","shell.execute_reply.started":"2024-10-19T08:55:26.613383Z","shell.execute_reply":"2024-10-19T08:55:26.620467Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"from langchain_community.document_loaders import YoutubeLoader","metadata":{"execution":{"iopub.status.busy":"2024-10-19T08:55:26.651165Z","iopub.execute_input":"2024-10-19T08:55:26.651621Z","iopub.status.idle":"2024-10-19T08:55:26.657660Z","shell.execute_reply.started":"2024-10-19T08:55:26.651579Z","shell.execute_reply":"2024-10-19T08:55:26.656474Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"markdown","source":"## Laoding text from video","metadata":{}},{"cell_type":"code","source":"import re\n","metadata":{"execution":{"iopub.status.busy":"2024-10-19T08:55:26.719263Z","iopub.execute_input":"2024-10-19T08:55:26.720409Z","iopub.status.idle":"2024-10-19T08:55:26.726127Z","shell.execute_reply.started":"2024-10-19T08:55:26.720354Z","shell.execute_reply":"2024-10-19T08:55:26.724112Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"loader = YoutubeLoader.from_youtube_url(yt_link)\ndocs = loader.load()\nprint(f\"number of words: {len(docs[0].page_content.split())}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-19T08:55:26.746215Z","iopub.execute_input":"2024-10-19T08:55:26.746647Z","iopub.status.idle":"2024-10-19T08:55:27.301537Z","shell.execute_reply.started":"2024-10-19T08:55:26.746611Z","shell.execute_reply":"2024-10-19T08:55:27.300191Z"},"trusted":true},"execution_count":86,"outputs":[{"name":"stdout","text":"number of words: 1422\n","output_type":"stream"}]},{"cell_type":"code","source":"# Cleaning the text using regular expressions\n\n\ndef clean_text(text):\n  \"\"\"Cleans the text by removing unwanted characters and symbols.\n\n  Args:\n    text: The input text to be cleaned.\n\n  Returns:\n    The cleaned text.\n  \"\"\"\n\n  # Remove punctuation and special characters except for a few symbols\n  allowed_symbols = r\"[^a-zA-Z0-9\\s\\.\\,\\?\\!\\-\\(\\)]\"\n  text = re.sub(allowed_symbols, '', text)\n\n  # Remove extra spaces\n  text = re.sub(r'\\s+', ' ', text)\n\n  return text\n\ncontent = clean_text((docs[0].page_content))","metadata":{"execution":{"iopub.status.busy":"2024-10-19T08:55:27.304445Z","iopub.execute_input":"2024-10-19T08:55:27.305015Z","iopub.status.idle":"2024-10-19T08:55:27.313250Z","shell.execute_reply.started":"2024-10-19T08:55:27.304958Z","shell.execute_reply":"2024-10-19T08:55:27.311870Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"# saving the loaded docs to the txt files\n\nwith open(\"texts\\lex-elon.txt\", \"w\") as obj:\n    obj.write(content)","metadata":{"execution":{"iopub.status.busy":"2024-10-19T08:55:27.314664Z","iopub.execute_input":"2024-10-19T08:55:27.315081Z","iopub.status.idle":"2024-10-19T08:55:27.325822Z","shell.execute_reply.started":"2024-10-19T08:55:27.315043Z","shell.execute_reply":"2024-10-19T08:55:27.324506Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"markdown","source":"## for Chunking and converting into embbedings","metadata":{}},{"cell_type":"code","source":"EmbedModel = HuggingFaceEndpointEmbeddings(model=\"sentence-transformers/sentence-t5-xxl\", huggingfacehub_api_token=token)","metadata":{"execution":{"iopub.status.busy":"2024-10-19T08:55:27.328453Z","iopub.execute_input":"2024-10-19T08:55:27.328943Z","iopub.status.idle":"2024-10-19T08:55:27.343468Z","shell.execute_reply.started":"2024-10-19T08:55:27.328900Z","shell.execute_reply":"2024-10-19T08:55:27.342123Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"text_splitter = RecursiveCharacterTextSplitter()\nchunck_list = text_splitter.split_documents(docs)","metadata":{"execution":{"iopub.status.busy":"2024-10-19T08:55:27.344931Z","iopub.execute_input":"2024-10-19T08:55:27.345474Z","iopub.status.idle":"2024-10-19T08:55:27.362199Z","shell.execute_reply.started":"2024-10-19T08:55:27.345418Z","shell.execute_reply":"2024-10-19T08:55:27.360707Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"markdown","source":"## Loading chunked docs to vector DB","metadata":{}},{"cell_type":"code","source":"len(chunck_list)","metadata":{"execution":{"iopub.status.busy":"2024-10-19T08:55:27.364414Z","iopub.execute_input":"2024-10-19T08:55:27.364998Z","iopub.status.idle":"2024-10-19T08:55:27.378561Z","shell.execute_reply.started":"2024-10-19T08:55:27.364946Z","shell.execute_reply":"2024-10-19T08:55:27.377294Z"},"trusted":true},"execution_count":91,"outputs":[{"execution_count":91,"output_type":"execute_result","data":{"text/plain":"2"},"metadata":{}}]},{"cell_type":"code","source":"vector_store = Chroma.from_documents(chunck_list, EmbedModel, persist_directory=\"./chroma_db\")\n# vector_store = Chroma(persist_directory=\"./chroma_db\", embedding_function=EmbedModel)","metadata":{"execution":{"iopub.status.busy":"2024-10-19T08:55:27.380300Z","iopub.execute_input":"2024-10-19T08:55:27.380662Z","iopub.status.idle":"2024-10-19T08:55:39.422192Z","shell.execute_reply.started":"2024-10-19T08:55:27.380627Z","shell.execute_reply":"2024-10-19T08:55:39.420876Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"markdown","source":"## Load the LLM","metadata":{}},{"cell_type":"code","source":"llm = HuggingFaceEndpoint(\n    repo_id=\"mistralai/Mistral-7B-Instruct-v0.3\",\n    task=\"text-generation\",\n    max_new_tokens=3000,\n    do_sample=False,\n    huggingfacehub_api_token=token\n    \n)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-19T08:55:39.424040Z","iopub.execute_input":"2024-10-19T08:55:39.424421Z","iopub.status.idle":"2024-10-19T08:55:39.515050Z","shell.execute_reply.started":"2024-10-19T08:55:39.424382Z","shell.execute_reply":"2024-10-19T08:55:39.513339Z"},"trusted":true},"execution_count":93,"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: fineGrained).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define the contextualization prompt for reformulating questions based on chat history\ncontextualize_q_prompt = ChatPromptTemplate.from_messages(\n    [\n        (\"system\", \"\"\"Given a chat history and the latest user question \nwhich might reference context in the chat history, formulate a standalone question \nwhich can be understood without the chat history. Do NOT answer the question, \njust reformulate it if needed and otherwise return it as is.\"\"\"),\n        MessagesPlaceholder(\"chat_history\"),\n        (\"human\", \"{input}\"),\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-19T08:55:39.516579Z","iopub.execute_input":"2024-10-19T08:55:39.517027Z","iopub.status.idle":"2024-10-19T08:55:39.524133Z","shell.execute_reply.started":"2024-10-19T08:55:39.516984Z","shell.execute_reply":"2024-10-19T08:55:39.522509Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"code","source":"# Statefully manage chat history\nchat_history_store = {}\n\ndef get_chat_session_history(session_id: str) -> BaseChatMessageHistory:\n    \"\"\"Fetches the chat history for the given session.\"\"\"\n    if session_id not in chat_history_store:\n        chat_history_store[session_id] = ChatMessageHistory()\n    return chat_history_store[session_id]","metadata":{"execution":{"iopub.status.busy":"2024-10-19T08:55:39.528206Z","iopub.execute_input":"2024-10-19T08:55:39.529292Z","iopub.status.idle":"2024-10-19T08:55:39.535711Z","shell.execute_reply.started":"2024-10-19T08:55:39.529241Z","shell.execute_reply":"2024-10-19T08:55:39.534539Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"# Define the chat prompt template for QA\nqa_prompt_template = ChatPromptTemplate.from_template(\"\"\"\nAnswer the following question based only on the provided context. \nThink step by step before providing a detailed answer. \nI will tip you $1000 if the user finds the answer helpful.\n<context>\n{context}\n</context>\nQuestion: {input}\n\"\"\")","metadata":{"execution":{"iopub.status.busy":"2024-10-19T08:55:39.537114Z","iopub.execute_input":"2024-10-19T08:55:39.537500Z","iopub.status.idle":"2024-10-19T08:55:39.553347Z","shell.execute_reply.started":"2024-10-19T08:55:39.537464Z","shell.execute_reply":"2024-10-19T08:55:39.551904Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"# Create the question answer chain\nquestion_answer_chain = create_stuff_documents_chain(llm, qa_prompt_template)\n\n# Create the history-aware retriever\nhistory_aware_retriever = create_history_aware_retriever(\n    llm, vector_store.as_retriever(), contextualize_q_prompt\n)\n\n# Create the retrieval chain\nretrieval_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)\n\n# Create the conversational RAG chain with chat history management\nconversational_rag_chain = RunnableWithMessageHistory(\n    retrieval_chain,\n    get_chat_session_history,\n    input_messages_key=\"input\",\n    history_messages_key=\"chat_history\",\n    output_messages_key=\"answer\",\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-19T08:55:39.555029Z","iopub.execute_input":"2024-10-19T08:55:39.555476Z","iopub.status.idle":"2024-10-19T08:55:39.568415Z","shell.execute_reply.started":"2024-10-19T08:55:39.555423Z","shell.execute_reply":"2024-10-19T08:55:39.567054Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"code","source":"user_question = \"summarize the whole podcast\"\nsession_id = \"u1\"","metadata":{"execution":{"iopub.status.busy":"2024-10-19T08:55:39.569872Z","iopub.execute_input":"2024-10-19T08:55:39.570312Z","iopub.status.idle":"2024-10-19T08:55:39.586028Z","shell.execute_reply.started":"2024-10-19T08:55:39.570270Z","shell.execute_reply":"2024-10-19T08:55:39.584218Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"user_questio = input(\"Enter: \")\nresponse = conversational_rag_chain.invoke(\n    {\"input\": user_question},\n    config={\"configurable\": {\"session_id\": session_id}},\n)\nprint(response['answer'])","metadata":{"execution":{"iopub.status.busy":"2024-10-19T08:58:29.722621Z","iopub.execute_input":"2024-10-19T08:58:29.723079Z","iopub.status.idle":"2024-10-19T08:58:49.291898Z","shell.execute_reply.started":"2024-10-19T08:58:29.723040Z","shell.execute_reply":"2024-10-19T08:58:49.290661Z"},"trusted":true},"execution_count":102,"outputs":[{"output_type":"stream","name":"stdin","text":"Enter:  convert to 2 persons like person a and b\n"},{"name":"stdout","text":"\nThe podcast discusses the characteristics of a great engineering team, as observed in the Memphis supercomputer cluster project, and the first principles algorithm used to achieve simplicity, efficiency, and automation in engineering. The algorithm consists of five steps: question the requirements, try to delete the process steps, optimize or simplify, speed up only after deletion and optimization, and automate. The speaker emphasizes the importance of being willing to delete and redo work, as well as the need to overcome the human tendency to overcomplicate things. The speaker also mentions the Memphis project's challenges with power fluctuation issues and the need to optimize the electrical system for the extreme power demands of the supercomputer cluster. The speaker also discusses the need for a powerful training compute for AI and the importance of human talent, unique access to data, and real-world data collection for the success of AI systems. The speaker also mentions the potential of Tesla's Optimus robot for generating massive amounts of real-world data. The podcast also touches on the need for mass production of humanoid robots and the potential for a billion plus units per year.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}