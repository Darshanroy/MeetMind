{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Task: MeetMind\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## 1. Requirements:"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T07:30:24.002316Z","iopub.status.busy":"2024-10-21T07:30:24.001763Z","iopub.status.idle":"2024-10-21T07:30:37.381264Z","shell.execute_reply":"2024-10-21T07:30:37.379684Z","shell.execute_reply.started":"2024-10-21T07:30:24.002232Z"},"trusted":true},"outputs":[],"source":["# ! pip install -q langchain langchain_chroma langchain_community langchain_core langchain_huggingface transformers\n","# ! pip install -qU langchain_huggingface\n","# ! pip install pytube\n","# ! pip install --upgrade --quiet  youtube-transcript-api\n","\n","# !pip install -qU langchain_pinecone\n","# !pip install -qU langchain_groq"]},{"cell_type":"markdown","metadata":{},"source":["## 2. Loading Libraries "]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T10:08:30.401207Z","iopub.status.busy":"2024-10-21T10:08:30.400785Z","iopub.status.idle":"2024-10-21T10:08:30.442547Z","shell.execute_reply":"2024-10-21T10:08:30.440913Z","shell.execute_reply.started":"2024-10-21T10:08:30.401168Z"},"trusted":true},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'langchain'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdotenv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_history_aware_retriever, create_retrieval_chain\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcombine_documents\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_stuff_documents_chain\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_chroma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Chroma\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain'"]}],"source":["import os\n","import re\n","import time\n","from dotenv import load_dotenv\n","from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n","from langchain.chains.combine_documents import create_stuff_documents_chain\n","from langchain_chroma import Chroma\n","from langchain_community.llms import HuggingFaceHub\n","from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n","from langchain_community.document_loaders import YoutubeLoader\n","from langchain_core.chat_history import BaseChatMessageHistory\n","from langchain_community.chat_message_histories import ChatMessageHistory\n","from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n","from langchain_core.runnables.history import RunnableWithMessageHistory\n","from langchain_text_splitters import RecursiveCharacterTextSplitter\n","from langchain_huggingface.embeddings import HuggingFaceEndpointEmbeddings\n","from langchain_huggingface import HuggingFaceEndpoint\n","from langchain.chains import HypotheticalDocumentEmbedder\n","from dataclasses import dataclass\n","from langchain.schema import Document\n"]},{"cell_type":"markdown","metadata":{},"source":["## 3. Links"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T10:08:38.960021Z","iopub.status.busy":"2024-10-21T10:08:38.959049Z","iopub.status.idle":"2024-10-21T10:08:38.965890Z","shell.execute_reply":"2024-10-21T10:08:38.964798Z","shell.execute_reply.started":"2024-10-21T10:08:38.959977Z"},"trusted":true},"outputs":[],"source":["@dataclass\n","class Credentials:\n","    token: str = \"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\"\n","    yt_link: str = \"https://www.youtube.com/live/UrfmlqHgZLA?si=gGsUOyKGz2zmltr9\"\n","    groq_api: str = \"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\"\n"]},{"cell_type":"markdown","metadata":{},"source":["## 4. Laoding text from video"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T07:30:39.332188Z","iopub.status.busy":"2024-10-21T07:30:39.331816Z","iopub.status.idle":"2024-10-21T07:30:39.984094Z","shell.execute_reply":"2024-10-21T07:30:39.982880Z","shell.execute_reply.started":"2024-10-21T07:30:39.332140Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["number of words: 13356\n"]}],"source":["def get_word_count_from_youtube_url(yt_link):\n","    \"\"\"Calculates the word count from a YouTube video link and returns the documents.\n","\n","    Args:\n","        yt_link (str): The URL of the YouTube video.\n","\n","    Returns:\n","        tuple: A tuple containing the number of words and the documents.\n","    \"\"\"\n","\n","    try:\n","        loader = YoutubeLoader.from_youtube_url(yt_link)\n","        docs = loader.load()\n","        word_count = len(docs[0].page_content.split())\n","        return word_count, docs\n","    except Exception as e:\n","        print(f\"Error loading YouTube video: {e}\")\n","        return 0, None\n","    \n","    \n","word_count, docs = get_word_count_from_youtube_url(Credentials.yt_link)\n","print(f\"Number of words: {word_count}\")"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T07:30:39.986113Z","iopub.status.busy":"2024-10-21T07:30:39.985718Z","iopub.status.idle":"2024-10-21T07:30:39.999985Z","shell.execute_reply":"2024-10-21T07:30:39.998515Z","shell.execute_reply.started":"2024-10-21T07:30:39.986072Z"},"trusted":true},"outputs":[],"source":["# Cleaning the text using regular expressions\n","def clean_text(text):\n","  \"\"\"Cleans the text by removing unwanted characters and symbols.\n","\n","  Args:\n","    text: The input text to be cleaned.\n","\n","  Returns:\n","    The cleaned text.\n","  \"\"\"\n","\n","  # Remove punctuation and special characters except for a few symbols\n","  allowed_symbols = r\"[^a-zA-Z0-9\\s\\.\\,\\?\\!\\-\\(\\)]\"\n","  text = re.sub(allowed_symbols, '', text)\n","\n","  # Remove extra spaces\n","  text = re.sub(r'\\s+', ' ', text)\n","\n","  return text\n","\n","content = clean_text((docs[0].page_content))\n","content = Document(page_content=content)\n"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T07:30:40.002747Z","iopub.status.busy":"2024-10-21T07:30:40.002196Z","iopub.status.idle":"2024-10-21T07:30:40.016057Z","shell.execute_reply":"2024-10-21T07:30:40.014575Z","shell.execute_reply.started":"2024-10-21T07:30:40.002696Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["13356\n"]}],"source":["# saving the loaded docs to the txt files\n","\n","with open(\"texts\\lex-elon.txt\", \"w\") as obj:\n","    obj.write(content)\n","    \n","print(len(content.split())) "]},{"cell_type":"markdown","metadata":{},"source":["## 5. for Chunking and converting into embbedings"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T07:30:40.018452Z","iopub.status.busy":"2024-10-21T07:30:40.017804Z","iopub.status.idle":"2024-10-21T07:30:40.240674Z","shell.execute_reply":"2024-10-21T07:30:40.239371Z","shell.execute_reply.started":"2024-10-21T07:30:40.018382Z"},"trusted":true},"outputs":[],"source":["EmbedModel = HuggingFaceEndpointEmbeddings(model=\"intfloat/multilingual-e5-large\", huggingfacehub_api_token=token)\n","\n","\n","# from langchain_pinecone import PineconeEmbeddings\n","# EmbedModel = PineconeEmbeddings(model=\"multilingual-e5-large\",pinecone_api_key='f55bd135-3e72-41d7-8665-55105bbf2e08')"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T07:30:40.243037Z","iopub.status.busy":"2024-10-21T07:30:40.242511Z","iopub.status.idle":"2024-10-21T07:30:40.314580Z","shell.execute_reply":"2024-10-21T07:30:40.312425Z","shell.execute_reply.started":"2024-10-21T07:30:40.242976Z"},"trusted":true},"outputs":[],"source":["text_splitter = RecursiveCharacterTextSplitter()\n","\n","chunck_list = text_splitter.split_documents(content)"]},{"cell_type":"markdown","metadata":{},"source":["## 6. Loading chunked docs to vector DB"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T07:30:40.320451Z","iopub.status.busy":"2024-10-21T07:30:40.319985Z","iopub.status.idle":"2024-10-21T07:30:40.329633Z","shell.execute_reply":"2024-10-21T07:30:40.328396Z","shell.execute_reply.started":"2024-10-21T07:30:40.320407Z"},"trusted":true},"outputs":[{"data":{"text/plain":["18"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["len(chunck_list)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T07:30:40.331564Z","iopub.status.busy":"2024-10-21T07:30:40.331135Z","iopub.status.idle":"2024-10-21T07:31:16.624545Z","shell.execute_reply":"2024-10-21T07:31:16.623032Z","shell.execute_reply.started":"2024-10-21T07:30:40.331517Z"},"trusted":true},"outputs":[],"source":["vector_store = Chroma.from_documents(chunck_list, EmbedModel, persist_directory=\"./chroma_db\")\n","# vector_store = Chroma(persist_directory=\"./chroma_db\", embedding_function=EmbedModel)"]},{"cell_type":"markdown","metadata":{},"source":["## 7. Load the LLM"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T07:31:16.626790Z","iopub.status.busy":"2024-10-21T07:31:16.626335Z","iopub.status.idle":"2024-10-21T07:31:16.762799Z","shell.execute_reply":"2024-10-21T07:31:16.761357Z","shell.execute_reply.started":"2024-10-21T07:31:16.626750Z"},"trusted":true},"outputs":[],"source":["from langchain_groq import ChatGroq\n","import  os\n","\n","llm=ChatGroq(groq_api_key=groq_api,\n","             model_name=\"Llama3-8b-8192\")"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T07:31:16.765006Z","iopub.status.busy":"2024-10-21T07:31:16.764549Z","iopub.status.idle":"2024-10-21T07:31:16.771365Z","shell.execute_reply":"2024-10-21T07:31:16.769907Z","shell.execute_reply.started":"2024-10-21T07:31:16.764958Z"},"trusted":true},"outputs":[],"source":["# llm = HuggingFaceEndpoint(\n","#     repo_id=\"mistralai/Mistral-7B-Instruct-v0.3\",\n","#     task=\"text-generation\",\n","#     max_new_tokens=3000,\n","#     do_sample=False,\n","#     huggingfacehub_api_token=token\n","    \n","# )"]},{"cell_type":"markdown","metadata":{},"source":["## 8. creating all the prompt templates"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T07:31:16.774271Z","iopub.status.busy":"2024-10-21T07:31:16.773613Z","iopub.status.idle":"2024-10-21T07:31:16.786859Z","shell.execute_reply":"2024-10-21T07:31:16.785702Z","shell.execute_reply.started":"2024-10-21T07:31:16.774201Z"},"trusted":true},"outputs":[],"source":["# Define the contextualization prompt for reformulating questions based on chat history\n","contextualize_q_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\", \"\"\"Given a chat history and the latest user question \n","which might reference context in the chat history, formulate a standalone question \n","which can be understood without the chat history. Do NOT answer the question, \n","just reformulate it if needed and otherwise return it as is.\"\"\"),\n","        MessagesPlaceholder(\"chat_history\"),\n","        (\"human\", \"{input}\"),\n","    ]\n",")"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T07:31:16.788968Z","iopub.status.busy":"2024-10-21T07:31:16.788486Z","iopub.status.idle":"2024-10-21T07:31:16.803908Z","shell.execute_reply":"2024-10-21T07:31:16.802627Z","shell.execute_reply.started":"2024-10-21T07:31:16.788913Z"},"trusted":true},"outputs":[],"source":["# Statefully manage chat history\n","chat_history_store = {}\n","\n","def get_chat_session_history(session_id: str) -> BaseChatMessageHistory:\n","    \"\"\"Fetches the chat history for the given session.\"\"\"\n","    if session_id not in chat_history_store:\n","        chat_history_store[session_id] = ChatMessageHistory()\n","    return chat_history_store[session_id]"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T07:31:16.806095Z","iopub.status.busy":"2024-10-21T07:31:16.805604Z","iopub.status.idle":"2024-10-21T07:31:16.816919Z","shell.execute_reply":"2024-10-21T07:31:16.815636Z","shell.execute_reply.started":"2024-10-21T07:31:16.806036Z"},"trusted":true},"outputs":[],"source":["# Define the chat prompt template for QA\n","qa_prompt_template = ChatPromptTemplate.from_template(\"\"\"\n","Answer the following question based only on the provided context. \n","Think step by step before providing a detailed answer. \n","I will tip you $1000 if the user finds the answer helpful.\n","<context>\n","{context}\n","</context>\n","Question: {input}\n","\"\"\")"]},{"cell_type":"markdown","metadata":{},"source":["## 9. Creating chains"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T07:31:16.818959Z","iopub.status.busy":"2024-10-21T07:31:16.818543Z","iopub.status.idle":"2024-10-21T07:31:16.838947Z","shell.execute_reply":"2024-10-21T07:31:16.837435Z","shell.execute_reply.started":"2024-10-21T07:31:16.818917Z"},"trusted":true},"outputs":[],"source":["# Create the question answer chain\n","question_answer_chain = create_stuff_documents_chain(llm, qa_prompt_template)\n","\n","# Create the history-aware retriever\n","history_aware_retriever = create_history_aware_retriever(\n","    llm, vector_store.as_retriever(), contextualize_q_prompt\n",")\n","\n","# Create the retrieval chain\n","retrieval_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)\n","\n","# Create the conversational RAG chain with chat history management\n","conversational_rag_chain = RunnableWithMessageHistory(\n","    retrieval_chain,\n","    get_chat_session_history,\n","    input_messages_key=\"input\",\n","    history_messages_key=\"chat_history\",\n","    output_messages_key=\"answer\",\n",")"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T07:31:16.841451Z","iopub.status.busy":"2024-10-21T07:31:16.840738Z","iopub.status.idle":"2024-10-21T07:31:16.854115Z","shell.execute_reply":"2024-10-21T07:31:16.852702Z","shell.execute_reply.started":"2024-10-21T07:31:16.841393Z"},"trusted":true},"outputs":[],"source":["user_question = \"Highlight the important points in the podcast!\"\n","session_id = \"u1\"\n"]},{"cell_type":"markdown","metadata":{},"source":["## 10. Inference "]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T07:31:16.856615Z","iopub.status.busy":"2024-10-21T07:31:16.856109Z","iopub.status.idle":"2024-10-21T07:31:18.020031Z","shell.execute_reply":"2024-10-21T07:31:18.018517Z","shell.execute_reply.started":"2024-10-21T07:31:16.856566Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Based on the provided context, here are the important points:\n","\n","1. **Full Tex search**: The speaker mentions that using old-style full Tex search to find technical terms can improve recall.\n","2. **Repository links**: The speaker shares links to the repository, a blog post, and an older blog post, and encourages the audience to clone the repository, submit bugs, and ask questions on the GitHub discussion thread.\n","3. **Data generation and fine-tuning**: The speaker discusses the process of data generation and fine-tuning, including the generation of a dataset, reformating files, and uploading to the fine-tuning API.\n","4. **Splitting data**: The speaker explains the importance of splitting data into training, validation, and evaluation sets in machine learning.\n","5. **Fining deployment and evaluation**: The speaker provides an end-to-end demonstration of how to do data generation, fine-tuning, deployment, and evaluation fully as code.\n","\n","These points highlight the main topics discussed in the podcast.\n"]}],"source":["# user_questio = input(\"Enter: \")\n","response = conversational_rag_chain.invoke(\n","    {\"input\": user_question},\n","    config={\"configurable\": {\"session_id\": session_id}},\n",")\n","print(response['answer'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30775,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
